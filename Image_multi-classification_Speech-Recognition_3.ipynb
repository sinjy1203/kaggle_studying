{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f353c7b",
   "metadata": {},
   "source": [
    "# WavCeption V1: a 1-D Inception approach (LB 0.76)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0ddae",
   "metadata": {},
   "source": [
    "## Load modules and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4218aa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import IPython\n",
    "from numpy.fft import rfft, irfft\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8f01e",
   "metadata": {},
   "source": [
    "## Noise generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69da0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ms(x):  # mean squared\n",
    "    return (np.abs(x)**2).mean()\n",
    "\n",
    "def normalize(y, x=None):\n",
    "    if x is not None:\n",
    "        x = ms(x)\n",
    "    else:\n",
    "        x = 1.0\n",
    "    return y * np.sqrt(x / ms(y))\n",
    "\n",
    "def white_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    return state.randn(N)\n",
    "\n",
    "def pink_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N % 2\n",
    "    X = state.randn(N // 2 + 1 + uneven) + 1j * state.randn(N // 2 + 1 + uneven)\n",
    "    S = np.sqrt(np.arange(len(X)) + 1.)\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def blue_noise(N, state=None):\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N % 2\n",
    "    X = state.randn(N // 2 + 1 + uneven) + 1j * state.randn(N // 2 + 1 + uneven)\n",
    "    S = np.sqrt(np.arange(len(X)))\n",
    "    y = (irfft(X * S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def brown_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise.\n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power decreases with -3 dB per octave.\n",
    "    Power density decreases with 6 dB per octave. \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X))+1)# Filter\n",
    "    y = (irfft(X/S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)\n",
    "\n",
    "def violet_noise(N, state=None):\n",
    "    \"\"\"\n",
    "    Violet noise. Power increases with 6 dB per octave. \n",
    "    \n",
    "    :param N: Amount of samples.\n",
    "    :param state: State of PRNG.\n",
    "    :type state: :class:`np.random.RandomState`\n",
    "    \n",
    "    Power increases with +9 dB per octave.\n",
    "    Power density increases with +6 dB per octave. \n",
    "    \n",
    "    \"\"\"\n",
    "    state = np.random.RandomState() if state is None else state\n",
    "    uneven = N%2\n",
    "    X = state.randn(N//2+1+uneven) + 1j * state.randn(N//2+1+uneven)\n",
    "    S = (np.arange(len(X)))# Filter\n",
    "    y = (irfft(X*S)).real\n",
    "    if uneven:\n",
    "        y = y[:-1]\n",
    "    return normalize(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3959f",
   "metadata": {},
   "source": [
    "## Tensorflow utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af05696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensorflow_configuration(device=\"0\", memory_fraction=1):\n",
    "    device = str(device)\n",
    "    config = tf.ConfigProto()\n",
    "    config.allow_soft_placement = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = memory_fraction\n",
    "    config.gpu_options.visible_device_list = device\n",
    "    return (config)\n",
    "\n",
    "def start_tensorflow_session(device=\"0\", memory_fraction=1):\n",
    "    return (tf.Session(config=get_tensorflow_configuration(device=device, memory_fraction=memory_fraction)))\n",
    "\n",
    "def get_summary_writer(session, logs_path, project_id, version_id):\n",
    "    path = logs_path / \"{}}_{}\".format(project_id, version_id)\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    summary_writer = tf.summary.FileWriter(path, graph_def=session.graph_def)\n",
    "    return (summary_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe23b4d",
   "metadata": {},
   "source": [
    "## Paths management module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c897f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"C:/Users/sinjy/jupyter_notebook/datasets/kaggle_datasets/speech\"\n",
    "OUTPUT_DIR = \"C:/Users/sinjy/jupyter_notebook/datasets/kaggle_predict\"\n",
    "def _norm_path(path):\n",
    "    def normalize_path(*args, **kwargs):\n",
    "        return os.path.normpath(path(*args, **kwargs))\n",
    "    return normalize_path\n",
    "\n",
    "def _assure_path_exists(path):\n",
    "    def assure_exists(*args, **kwargs):\n",
    "        p = path(*args, **kwargs)\n",
    "        assert os.path.exists(p), \"the following path does not exist: '{}'\".format(p)\n",
    "        return p\n",
    "    return assure_exists\n",
    "\n",
    "def _is_output_path(path):\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence_or_create_it(*args, **kwargs):\n",
    "        if not os.path.exists(path(*args, **kwargs)):\n",
    "            \"Path does not exist... creating it: {}\".format(path(*args, **kwargs))\n",
    "            os.makedirs(path(*args, **kwargs))\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence_or_create_it\n",
    "\n",
    "def _is_input_path(path):\n",
    "    @_norm_path\n",
    "    @_assure_path_exists\n",
    "    def check_existence(*args, **kwargs):\n",
    "        return path(*args, **kwargs)\n",
    "    return check_existence\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_path():\n",
    "    path = DATA_DIR + \"/train\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_test_path():\n",
    "    path = DATA_DIR + \"/test\"\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_train_audio_path():\n",
    "    path = os.path.join(get_train_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_input_path\n",
    "def get_scoring_audio_path():\n",
    "    path = os.path.join(get_test_path(), \"audio\")\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_submissions_path():\n",
    "    path = OUTPUT_DIR + \"/output\"\n",
    "    return path\n",
    "\n",
    "@_is_output_path\n",
    "def get_silence_path():\n",
    "    path = OUTPUT_DIR + \"/silence\"\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88493c0b",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8c514c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "def batching(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, n):\n",
    "        yield iterable[ndx: min(ndx + n, l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f48d4b",
   "metadata": {},
   "source": [
    "## Data Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63c5c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav(filepath, pad=True):\n",
    "    sample_rate, x = wavfile.read(filepath)\n",
    "    target = os.path.split(os.path.split(filepath)[0])[1]\n",
    "    assert sample_rate == 16000\n",
    "    if pad:\n",
    "        return np.pad(x, (0, 16000-len(x)), mode='constant') / 32768, target\n",
    "    else:\n",
    "        return x / 32768, target\n",
    "    \n",
    "def get_batcher(list_of_paths, batch_size, label_encoder=None, scoring=False):\n",
    "    for filepaths in batching(list_of_paths, batch_size):\n",
    "        wavs, targets = zip(*list(map(read_wav, filepaths)))\n",
    "        if scoring:\n",
    "            yield np.expand_dims(np.row_stack(wavs), 2), filepaths\n",
    "        else:\n",
    "            if label_encoder is None:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.row_stack(targets)\n",
    "            else:\n",
    "                yield np.expand_dims(np.row_stack(wavs), 2), np.expand_dims(label_encoder.transform(np.squeeze(targets)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819aeba8",
   "metadata": {},
   "source": [
    "## Architecture building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c209e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(object):\n",
    "    def __init__(self, epsilon=1e-5, momentum=0.999, name='batch_norm'):\n",
    "        with tf.variable_scope(name):\n",
    "            self.epsilon = epsilon\n",
    "            self.momentum = momentum\n",
    "            self.name = name\n",
    "    \n",
    "    def __call__(self, x, train=True):\n",
    "        return tf.contrib.layers.batch_norm(\n",
    "                    x, decay=self.momentum, updates_collections=None, \n",
    "                    epsilon=self.epsilon, scale=True, is_training=train, \n",
    "                    scope=self.name)\n",
    "    \n",
    "def inception_1d(x, is_train, depth, norm_function, activ_function, name):\n",
    "    with tf.variable_scope(name):\n",
    "        x_norm = norm_function(name='norm_input')(x, train=is_train)\n",
    "        \n",
    "        branch_conv_1_1 = tf.layers.conv1d(inputs=x_norm, filters=16*depth, kernel_size=1,\n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_1_1\")\n",
    "        branch_conv_1_1 = norm_function(name=\"norm_conv_1_1\")(branch_conv_1_1, train=is_train)\n",
    "        branch_conv_1_1 = activ_function(branch_conv_1_1, \"activation_1_1\")\n",
    "        \n",
    "        \n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_1\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_1\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_1\")\n",
    "        \n",
    "        branch_conv_3_3 = tf.layers.conv1d(inputs=branch_conv_3_3, filters=32*depth, kernel_size=3, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_3_3_2\")\n",
    "        branch_conv_3_3 = norm_function(name=\"norm_conv_3_3_2\")(branch_conv_3_3, train=is_train)\n",
    "        branch_conv_3_3 = activ_function(branch_conv_3_3, \"activation_3_3_2\")\n",
    "        \n",
    "        \n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_1\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_1\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_1\")\n",
    "\n",
    "        branch_conv_5_5 = tf.layers.conv1d(inputs=branch_conv_5_5, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_5_5_2\")\n",
    "        branch_conv_5_5 = norm_function(name=\"norm_conv_5_5_2\")(branch_conv_5_5, train=is_train)\n",
    "        branch_conv_5_5 = activ_function(branch_conv_5_5, \"activation_5_5_2\")\n",
    "        \n",
    "        \n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=x_norm, filters=16, kernel_size=1, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_1\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_1\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_1\")\n",
    "\n",
    "        branch_conv_7_7 = tf.layers.conv1d(inputs=branch_conv_7_7, filters=32*depth, kernel_size=5, \n",
    "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                           padding=\"same\", name=\"conv_7_7_2\")\n",
    "        branch_conv_7_7 = norm_function(name=\"norm_conv_7_7_2\")(branch_conv_7_7, train=is_train)\n",
    "        branch_conv_7_7 = activ_function(branch_conv_7_7, \"activation_7_7_2\")\n",
    "        \n",
    "        \n",
    "        branch_maxpool_3_3 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"maxpool_3\")\n",
    "        branch_maxpool_3_3 = norm_function(name=\"norm_maxpool_3_3\")(branch_maxpool_3_3, train=is_train)\n",
    "        branch_maxpool_3_3 = tf.layers.conv1d(inputs=branch_maxpool_3_3, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_3\")\n",
    "        \n",
    "        \n",
    "        branch_maxpool_5_5 = tf.layers.max_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"maxpool_5\")\n",
    "        branch_maxpool_5_5 = norm_function(name=\"norm_maxpool_5_5\")(branch_maxpool_5_5, train=is_train)\n",
    "        branch_maxpool_5_5 = tf.layers.conv1d(inputs=branch_maxpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_maxpool_5\")\n",
    "        \n",
    "        \n",
    "        branch_avgpool_3_3 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=3, strides=1, padding=\"same\", name=\"avgpool_3\")\n",
    "        branch_avgpool_3_3 = norm_function(name=\"norm_avgpool_3_3\")(branch_avgpool_3_3, train=is_train)\n",
    "        branch_avgpool_3_3 = tf.layers.conv1d(inputs=branch_avgpool_3_3, filters=16, kernel_size=1,\n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_3\")\n",
    "        \n",
    "        \n",
    "        branch_avgpool_5_5 = tf.layers.average_pooling1d(inputs=x_norm, pool_size=5, strides=1, padding=\"same\", name=\"avgpool_5\")\n",
    "        branch_avgpool_5_5 = norm_function(name=\"norm_avgpool_5_5\")(branch_avgpool_5_5, train=is_train)\n",
    "        branch_avgpool_5_5 = tf.layers.conv1d(inputs=branch_avgpool_5_5, filters=16, kernel_size=1, \n",
    "                                              kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                                              padding=\"same\", name=\"conv_avgpool_5\")\n",
    "        \n",
    "        \n",
    "        output = tf.concat([branch_conv_1_1, branch_conv_3_3, branch_conv_5_5, branch_conv_7_7, branch_maxpool_3_3, \n",
    "                           branch_maxpool_5_5, branch_avgpool_3_3, branch_avgpool_5_5], axis=-1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1086080",
   "metadata": {},
   "source": [
    "## Load and prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fffe2174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinjy\\anaconda3\\envs\\machine-learning\\lib\\site-packages\\ipykernel_launcher.py:2: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "filepaths_noise = glob.glob(\n",
    "    os.path.join(get_train_audio_path(), '_background_noise_', '*.wav'))\n",
    "\n",
    "noise = np.concatenate(list(map(lambda x: read_wav(x, False)[0], filepaths_noise)))\n",
    "noise = np.concatenate([noise, noise[::-1]])\n",
    "synthetic_noise = np.concatenate([white_noise(N=16000*30, state=np.random.RandomState(655321)), \n",
    "                                  blue_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  pink_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  brown_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  violet_noise(N=16000*30, state=np.random.RandomState(655321)),\n",
    "                                  np.zeros(16000*60)])\n",
    "synthetic_noise /= np.max(np.abs(synthetic_noise))\n",
    "synthetic_noise = np.concatenate([synthetic_noise, (synthetic_noise + synthetic_noise[::-1])/2])\n",
    "all_noise = np.concatenate([noise, synthetic_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06c11ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████████▏                                      | 3965/8000 [00:08<00:08, 470.34it/s]C:\\Users\\sinjy\\anaconda3\\envs\\machine-learning\\lib\\site-packages\\ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 8000/8000 [00:17<00:00, 456.53it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(655321)\n",
    "random.seed(655321)\n",
    "\n",
    "path = get_silence_path()\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "for noise_clip_no in tqdm(range(8000)):\n",
    "    if noise_clip_no <= 4000:\n",
    "        idx = np.random.randint(0, len(noise) - 16000)\n",
    "        clip = noise[idx: (idx+16000)]\n",
    "    else:\n",
    "        idx = np.random.randint(0, len(synthetic_noise)-16000)\n",
    "        clip = synthetic_noise[idx:(idx+16000)]\n",
    "    wavfile.write(os.path.join(path, \"{0:04d}.wav\".format(noise_clip_no)), \n",
    "                  16000, ((32767*clip/np.max(np.abs(clip))).astype(np.int16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b4d2217",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = glob.glob(os.path.join(get_train_audio_path(), \"**/*.wav\"), recursive=True)\n",
    "filepaths += glob.glob(os.path.join(get_silence_path(), \"**/*.wav\"), recursive=True)\n",
    "filepaths = list(filter(lambda fp: \"_background_noise_\" not in fp, filepaths))\n",
    "validation_list = open(os.path.join(get_train_path(), \"validation_list.txt\")).readlines()\n",
    "test_list = open(os.path.join(get_train_path(), \"testing_list.txt\")).readlines()\n",
    "validation_list = list(map(lambda x: x.replace('/', '\\\\'), validation_list))\n",
    "test_list = list(map(lambda x: x.replace('/', '\\\\'), test_list))\n",
    "validation_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), validation_list))\n",
    "testing_list = list(map(lambda fn: os.path.join(get_train_audio_path(), fn.strip()), test_list))\n",
    "training_list = np.setdiff1d(filepaths, validation_list+testing_list).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "42fcff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(655321)\n",
    "random.shuffle(filepaths)\n",
    "random.shuffle(validation_list)\n",
    "random.shuffle(testing_list)\n",
    "random.shuffle(training_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "008538f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "assert all(map(lambda fp: os.path.splitext(fp)[1] == '.wav', filepaths))\n",
    "assert len(filepaths) == 64727 - 6 + 8000\n",
    "assert len(training_list) == len(filepaths) - 6798 - 6835 \n",
    "assert len(validation_list) == 6798\n",
    "assert len(testing_list) == 6835\n",
    "\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), validation_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), testing_list))\n",
    "assert all(map(lambda fn: os.path.exists(os.path.join(fn)), training_list))\n",
    "assert set(validation_list + testing_list + training_list) == set(filepaths)\n",
    "\n",
    "assert len(np.intersect1d(validation_list, testing_list))==0\n",
    "assert len(np.intersect1d(training_list, testing_list))==0\n",
    "assert len(np.intersect1d(training_list, validation_list))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d88fcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'no': 2375,\n",
       "         'yes': 2377,\n",
       "         'stop': 2380,\n",
       "         'nine': 2364,\n",
       "         'left': 2353,\n",
       "         'dog': 1746,\n",
       "         'wow': 1745,\n",
       "         'up': 2375,\n",
       "         'one': 2370,\n",
       "         'six': 2369,\n",
       "         'zero': 2376,\n",
       "         'two': 2373,\n",
       "         'sheila': 1734,\n",
       "         'tree': 1733,\n",
       "         'silence': 8000,\n",
       "         'four': 2372,\n",
       "         'marvin': 1746,\n",
       "         'bed': 1713,\n",
       "         'right': 2367,\n",
       "         'seven': 2377,\n",
       "         'cat': 1733,\n",
       "         'eight': 2352,\n",
       "         'five': 2357,\n",
       "         'on': 2367,\n",
       "         'happy': 1742,\n",
       "         'off': 2357,\n",
       "         'three': 2356,\n",
       "         'go': 2372,\n",
       "         'down': 2359,\n",
       "         'bird': 1731,\n",
       "         'house': 1750})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinal_classes = list(set(map(lambda fp: os.path.split(os.path.split(fp)[0])[1], filepaths)))\n",
    "le_classes = LabelEncoder().fit(cardinal_classes)\n",
    "Counter(map(lambda fp: os.path.split(os.path.split(fp)[0])[1], filepaths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daf54e0",
   "metadata": {},
   "source": [
    "### quick data preparation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "071c2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_gen_test = get_batcher(filepaths, 1000)\n",
    "batch_a_wav, batch_a_target = next(_gen_test)\n",
    "batch_b_wav, batch_b_target = next(_gen_test)\n",
    "_gen_test_le = get_batcher(filepaths, 1000, label_encoder=le_classes)\n",
    "batch_le_wav, batch_le_target = next(_gen_test_le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0a3be01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert batch_a_wav.shape == (1000, 16000, 1)\n",
    "assert batch_le_wav.shape == (1000, 16000, 1)\n",
    "assert batch_a_wav.shape == batch_b_wav.shape == batch_le_wav.shape\n",
    "\n",
    "assert np.sum(np.abs(batch_a_wav-batch_b_wav)) != 0\n",
    "assert len(batch_a_target) == len(batch_b_target) == len(batch_le_target)\n",
    "assert any(batch_a_target != batch_b_target)\n",
    "\n",
    "assert all(batch_le_target == np.expand_dims(le_classes.transform(np.squeeze(batch_a_target)), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0395b360",
   "metadata": {},
   "source": [
    "## Architecture design"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
