{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13691d34",
   "metadata": {},
   "source": [
    "# XGBoost CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe33e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 1000\n",
    "OPTIMIZE_ROUNDS = True\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee3c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c15a86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f540175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None, val_series=None, tst_series=None, \n",
    "                 target=None, min_samples_leaf=1, smoothing=1,\n",
    "                 noise_level=0):\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    \n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg(['mean', 'count'])\n",
    "    smoothing = 1 / (1 + np.exp(-(averages['count'] - min_samples_leaf) / smoothing))\n",
    "    prior = target.mean()\n",
    "    \n",
    "    averages[target.name] = prior * (1 - smoothing) + averages['mean'] * smoothing\n",
    "    averages.drop(['mean', 'count'], axis=1, inplace=True)\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left'\n",
    "    )['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    \n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left'\n",
    "    )['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_val_series.index = val_series.index\n",
    "    \n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left'\n",
    "    )['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    \n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69439af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_dir = Path('C:/Users/sinjy/jupyter_notebook/datasets/kaggle_datasets/porto-seguro-safe-driver-prediction_dataset')\n",
    "train_df = pd.read_csv(data_dir / 'train.csv', na_values='-1')\n",
    "test_df = pd.read_csv(data_dir / 'test.csv', na_values='-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b830736",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f2df65",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d0275c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.1"
     ]
    }
   ],
   "source": [
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f' % (name1, n_c+1, (time.time()-start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "    train_features.append(name1)\n",
    "    \n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "f_cats = [f for f in X.columns if \"_cat\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9b03f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_car_13',\n",
       " 'ps_reg_03',\n",
       " 'ps_ind_05_cat',\n",
       " 'ps_ind_03',\n",
       " 'ps_ind_15',\n",
       " 'ps_reg_02',\n",
       " 'ps_car_14',\n",
       " 'ps_car_12',\n",
       " 'ps_car_01_cat',\n",
       " 'ps_car_07_cat',\n",
       " 'ps_ind_17_bin',\n",
       " 'ps_car_03_cat',\n",
       " 'ps_reg_01',\n",
       " 'ps_car_15',\n",
       " 'ps_ind_01',\n",
       " 'ps_ind_16_bin',\n",
       " 'ps_ind_07_bin',\n",
       " 'ps_car_06_cat',\n",
       " 'ps_car_04_cat',\n",
       " 'ps_ind_06_bin',\n",
       " 'ps_car_09_cat',\n",
       " 'ps_car_02_cat',\n",
       " 'ps_ind_02_cat',\n",
       " 'ps_car_11',\n",
       " 'ps_car_05_cat',\n",
       " 'ps_calc_09',\n",
       " 'ps_calc_05',\n",
       " 'ps_ind_08_bin',\n",
       " 'ps_car_08_cat',\n",
       " 'ps_ind_09_bin',\n",
       " 'ps_ind_04_cat',\n",
       " 'ps_ind_18_bin',\n",
       " 'ps_ind_12_bin',\n",
       " 'ps_ind_14',\n",
       " 'ps_reg_01_plus_ps_car_02_cat',\n",
       " 'ps_reg_01_plus_ps_car_04_cat']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c8820a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 21,  1, 23, 22, 17, 14, 11,  9, 16,  6,  3,  5, 20,  2,  8, 18,\n",
       "       13, 10,  0, 15,  7, 24, 12])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['ps_reg_01_plus_ps_car_02_cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b639ae89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7, 0.8, 0. , 0.9, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['ps_reg_01'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3447f1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa53848",
   "metadata": {},
   "source": [
    "## set up folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e25a6698",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "kf = KFold(n_splits=K, random_state=1, shuffle=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209de1da",
   "metadata": {},
   "source": [
    "## set up classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33e519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators=MAX_ROUNDS,\n",
    "    max_depth = 4,\n",
    "    objective='binary:logistic',\n",
    "    subsample=.8,\n",
    "    min_child_weight=6,\n",
    "    colsample_bytree=.8,\n",
    "    scale_pos_weight=1.6,\n",
    "    gamma=10,\n",
    "    reg_alpha=8,\n",
    "    reg_lambda=1.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b0afc",
   "metadata": {},
   "source": [
    "## Run CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7345037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 0\n",
      "[13:32:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best N trees =  73\n",
      "Best gini =  -0.284256\n",
      "Gini =  0.2842555514454962\n",
      "\n",
      "Fold 1\n",
      "[13:34:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best N trees =  91\n",
      "Best gini =  -0.274039\n",
      "Gini =  0.27403899702489065\n",
      "\n",
      "Fold 2\n",
      "[13:35:48] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best N trees =  127\n",
      "Best gini =  -0.271439\n",
      "Gini =  0.27143867206652905\n",
      "\n",
      "Fold 3\n",
      "[13:37:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best N trees =  69\n",
      "Best gini =  -0.296468\n",
      "Gini =  0.2964677275624653\n",
      "\n",
      "Fold 4\n",
      "[13:38:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best N trees =  57\n",
      "Best gini =  -0.279345\n",
      "Gini =  0.27934535450161424\n",
      "\n",
      "Gini for full training set: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2807212030804275"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index, :].copy(), X.iloc[test_index, :].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print(\"\\nFold\", i)\n",
    "    \n",
    "    for f in f_cats:\n",
    "        X_train[f+'_avg'], X_valid[f+\"_avg\"], X_test[f+\"_avg\"] = \\\n",
    "            target_encode(\n",
    "                trn_series=X_train[f],\n",
    "                val_series=X_valid[f],\n",
    "                tst_series=X_test[f],\n",
    "                target=y_train,\n",
    "                min_samples_leaf=200,\n",
    "                smoothing=10,\n",
    "                noise_level=0\n",
    "            )\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set = [(X_valid, y_valid)]\n",
    "        fit_model = model.fit(X_train, y_train,\n",
    "                             eval_set=eval_set,\n",
    "                             eval_metric=gini_xgb,\n",
    "                             early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                             verbose=False)\n",
    "        print(\"Best N trees = \", model.best_ntree_limit)\n",
    "        print(\"Best gini = \", model.best_score)\n",
    "    else:\n",
    "        fit_model = model.fit(X_train, y_train)\n",
    "\n",
    "    pred = fit_model.predict_proba(X_valid)[:, 1]\n",
    "    print(\"Gini = \", eval_gini(y_valid, pred))\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    del X_test, X_train, X_valid, y_train\n",
    "    \n",
    "y_test_pred /= K\n",
    "\n",
    "print(\"\\nGini for full training set: \")\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "007bf6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dir = Path('C:/Users/sinjy/jupyter_notebook/datasets/kaggle_predict')\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv(predict_dir / 'porto3_predict.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1af07",
   "metadata": {},
   "source": [
    "## test score: 0.28629"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
