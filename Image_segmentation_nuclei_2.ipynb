{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf82db6",
   "metadata": {},
   "source": [
    "# Keras U-Net starter - LB 0.277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96b43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinjy\\anaconda3\\envs\\machine-learning\\lib\\site-packages\\skimage\\io\\manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from tensorflow.keras import backend as K\n",
    "import tensorflow.compat.v1.keras.backend as K\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63fbab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "ROOT_DIR = Path('C:/Users/sinjy/jupyter_notebook/datasets')\n",
    "DATA_DIR = ROOT_DIR / 'kaggle_datasets' / 'nuclei'\n",
    "TRAIN_PATH = DATA_DIR / 'stage1_train'\n",
    "TEST_PATH = DATA_DIR / 'stage1_test'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b863797",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83866ed",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c87ca8",
   "metadata": {},
   "source": [
    "### resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d4b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinjy\\anaconda3\\envs\\machine-learning\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "  0%|                                                                                          | 0/670 [00:00<?, ?it/s]C:\\Users\\sinjy\\anaconda3\\envs\\machine-learning\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 670/670 [05:52<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ...')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH / id_\n",
    "    img = imread(path / 'images' / (id_ + '.png'))[:, :, :IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    for mask_file in next(os.walk(path / 'masks'))[2]:\n",
    "        mask_ = imread(path / 'masks' / mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True),\n",
    "                               axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66aae7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 65/65 [00:01<00:00, 36.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ...')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH / id_\n",
    "    img = imread(path / 'images' / (id_ + '.png'))[:, :, :IMG_CHANNELS]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e65e9",
   "metadata": {},
   "source": [
    "### check mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed7b8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061fbdcc",
   "metadata": {},
   "source": [
    "## Create our Keras metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "004ec961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.run_functions_eagerly(True)\n",
    "def mean_iou(y_true, y_pred):\n",
    "    meaniou = tf.keras.metrics.MeanIoU(2)\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.cast(y_pred > t, tf.int32)\n",
    "        score = meaniou(y_true, y_pred_)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "# class MeanIou(tf.keras.metrics.Metric):\n",
    "#     def __init__(self):\n",
    "#         super(MeanIou, self).__init__()\n",
    "#         self.mean_iou = tf.keras.metrics.MeanIoU(2)\n",
    "    \n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#         prec = []\n",
    "#         for t in np.arange(0.5, 1.0, 0.05):\n",
    "#             y_pred_ = tf.cast(y_pred > t, tf.int32)\n",
    "#             score = self.mean_iou(y_true, y_pred_)\n",
    "#             prec.append(score)\n",
    "#         self.ans =  K.mean(K.stack(prec), axis=0)\n",
    "    \n",
    "#     def result(self):\n",
    "#         return self.ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc329d",
   "metadata": {},
   "source": [
    "## Build and train our neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d8165",
   "metadata": {},
   "source": [
    "### Build U-Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5d4ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, pool):\n",
    "        super(DownConv, self).__init__()\n",
    "        self.pool = pool\n",
    "        self.c1 = Conv2D(\n",
    "            filters, (3, 3), activation='elu', kernel_initializer='he_normal', \n",
    "            padding='same')\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.c2 = Conv2D(\n",
    "            filters, (3, 3), activation='elu', kernel_initializer='he_normal', \n",
    "            padding='same')\n",
    "        if pool:\n",
    "            self.pool = MaxPooling2D((2, 2))\n",
    "    def call(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.dropout(x)\n",
    "        c = self.c2(x)\n",
    "        if self.pool:\n",
    "            p = self.pool(c)\n",
    "            return c, p\n",
    "        return c\n",
    "\n",
    "class UpConv(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(UpConv, self).__init__()\n",
    "        self.ct1 = Conv2DTranspose(filters, (2, 2), strides=(2, 2), \n",
    "                                   padding='same')\n",
    "        self.c1 = Conv2D(\n",
    "            filters, (3, 3), activation='elu', kernel_initializer='he_normal', \n",
    "            padding='same')\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.c2 = Conv2D(\n",
    "            filters, (3, 3), activation='elu', kernel_initializer='he_normal', \n",
    "            padding='same')\n",
    "    def call(self, x, d):\n",
    "        x = self.ct1(x)\n",
    "        x = concatenate([x, d])\n",
    "        x = self.c1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.c2(x)\n",
    "        return x\n",
    "    \n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters_lst):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.blocks = [DownConv(filters, True) for filters in filters_lst]\n",
    "        self.conv = DownConv(256, False)\n",
    "    def call(self, x):\n",
    "        c_lst = []\n",
    "        p = x\n",
    "        for block in self.blocks:\n",
    "            c, p = block(p)\n",
    "            c_lst += [c]\n",
    "        p = self.conv(p)\n",
    "        return p, c_lst\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters_lst):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.blocks = [UpConv(filters) for filters in filters_lst[::-1]]\n",
    "        self.conv = Conv2D(1, (1, 1), activation='sigmoid')\n",
    "    def call(self, p, c_lst):\n",
    "        for block, c in zip(self.blocks, c_lst[::-1]):\n",
    "            p = block(p, c)\n",
    "        p = self.conv(p)\n",
    "        return p\n",
    "    \n",
    "class UNet(tf.keras.Model):\n",
    "    def __init__(self, filters_lst=[16, 32, 64, 128]):\n",
    "        super(UNet, self).__init__()\n",
    "        self.scaler = Lambda(lambda x: x / 255)\n",
    "        self.encoder = Encoder(filters_lst)\n",
    "        self.decoder = Decoder(filters_lst)\n",
    "    def call(self, x):\n",
    "        x = self.scaler(x)\n",
    "        p, c_lst = self.encoder(x)\n",
    "        y = self.decoder(p, c_lst)\n",
    "        return y\n",
    "    def summary(self):\n",
    "        x = tf.keras.layers.Input(shape=[IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS])\n",
    "        model = tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "48446735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 128, 128, 3)  0           input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encoder_12 (Encoder)            ((None, 8, 8, 256),  1178768     lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder_12 (Decoder)            (None, 128, 128, 1)  762337      encoder_12[0][0]                 \n",
      "                                                                 encoder_12[0][1]                 \n",
      "                                                                 encoder_12[0][2]                 \n",
      "                                                                 encoder_12[0][3]                 \n",
      "                                                                 encoder_12[0][4]                 \n",
      "==================================================================================================\n",
      "Total params: 1,941,105\n",
      "Trainable params: 1,941,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = UNet()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "506b2afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "38/38 [==============================] - 61s 2s/step - loss: 0.2095 - mean_iou: 0.7739 - val_loss: 0.4510 - val_mean_iou: 0.7590\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.45100, saving model to C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as down_conv_64_layer_call_and_return_conditional_losses, down_conv_64_layer_call_fn, conv2d_265_layer_call_and_return_conditional_losses, conv2d_265_layer_call_fn, down_conv_60_layer_call_and_return_conditional_losses while saving (showing 5 of 185). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "38/38 [==============================] - 68s 2s/step - loss: 0.1606 - mean_iou: 0.8290 - val_loss: 0.2495 - val_mean_iou: 0.7920\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.45100 to 0.24955, saving model to C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as down_conv_64_layer_call_and_return_conditional_losses, down_conv_64_layer_call_fn, conv2d_265_layer_call_and_return_conditional_losses, conv2d_265_layer_call_fn, down_conv_60_layer_call_and_return_conditional_losses while saving (showing 5 of 185). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "38/38 [==============================] - 63s 2s/step - loss: 0.1398 - mean_iou: 0.8533 - val_loss: 0.1518 - val_mean_iou: 0.8553\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24955 to 0.15176, saving model to C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as down_conv_64_layer_call_and_return_conditional_losses, down_conv_64_layer_call_fn, conv2d_265_layer_call_and_return_conditional_losses, conv2d_265_layer_call_fn, down_conv_60_layer_call_and_return_conditional_losses while saving (showing 5 of 185). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "38/38 [==============================] - 63s 2s/step - loss: 0.1282 - mean_iou: 0.8631 - val_loss: 0.1510 - val_mean_iou: 0.8574\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15176 to 0.15100, saving model to C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as down_conv_64_layer_call_and_return_conditional_losses, down_conv_64_layer_call_fn, conv2d_265_layer_call_and_return_conditional_losses, conv2d_265_layer_call_fn, down_conv_60_layer_call_and_return_conditional_losses while saving (showing 5 of 185). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "38/38 [==============================] - 64s 2s/step - loss: 0.1333 - mean_iou: 0.8615 - val_loss: 0.2053 - val_mean_iou: 0.8234\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15100\n",
      "Epoch 6/50\n",
      "38/38 [==============================] - 64s 2s/step - loss: 0.1292 - mean_iou: 0.8617 - val_loss: 0.1162 - val_mean_iou: 0.8820\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15100 to 0.11622, saving model to C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as down_conv_64_layer_call_and_return_conditional_losses, down_conv_64_layer_call_fn, conv2d_265_layer_call_and_return_conditional_losses, conv2d_265_layer_call_fn, down_conv_60_layer_call_and_return_conditional_losses while saving (showing 5 of 185). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "38/38 [==============================] - 64s 2s/step - loss: 0.1156 - mean_iou: 0.8771 - val_loss: 0.0993 - val_mean_iou: 0.9006\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.11622 to 0.09926, saving model to C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as down_conv_64_layer_call_and_return_conditional_losses, down_conv_64_layer_call_fn, conv2d_265_layer_call_and_return_conditional_losses, conv2d_265_layer_call_fn, down_conv_60_layer_call_and_return_conditional_losses while saving (showing 5 of 185). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "38/38 [==============================] - 64s 2s/step - loss: 0.1106 - mean_iou: 0.8815 - val_loss: 0.1346 - val_mean_iou: 0.8711\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09926\n",
      "Epoch 9/50\n",
      "38/38 [==============================] - 65s 2s/step - loss: 0.1069 - mean_iou: 0.8852 - val_loss: 0.1096 - val_mean_iou: 0.8889\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09926\n",
      "Epoch 10/50\n",
      "38/38 [==============================] - 65s 2s/step - loss: 0.1068 - mean_iou: 0.8868 - val_loss: 0.1122 - val_mean_iou: 0.8816\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09926\n",
      "Epoch 11/50\n",
      "38/38 [==============================] - 65s 2s/step - loss: 0.1091 - mean_iou: 0.8845 - val_loss: 0.0945 - val_mean_iou: 0.9054\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09926 to 0.09450, saving model to C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as down_conv_64_layer_call_and_return_conditional_losses, down_conv_64_layer_call_fn, conv2d_265_layer_call_and_return_conditional_losses, conv2d_265_layer_call_fn, down_conv_60_layer_call_and_return_conditional_losses while saving (showing 5 of 185). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "38/38 [==============================] - 65s 2s/step - loss: 0.1041 - mean_iou: 0.8895 - val_loss: 0.0985 - val_mean_iou: 0.8884\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09450\n",
      "Epoch 13/50\n",
      "38/38 [==============================] - 68s 2s/step - loss: 0.1036 - mean_iou: 0.8893 - val_loss: 0.0890 - val_mean_iou: 0.9096\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.09450 to 0.08903, saving model to C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as down_conv_64_layer_call_and_return_conditional_losses, down_conv_64_layer_call_fn, conv2d_265_layer_call_and_return_conditional_losses, conv2d_265_layer_call_fn, down_conv_60_layer_call_and_return_conditional_losses while saving (showing 5 of 185). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "38/38 [==============================] - 69s 2s/step - loss: 0.1000 - mean_iou: 0.8917 - val_loss: 0.0933 - val_mean_iou: 0.9002\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.08903\n",
      "Epoch 15/50\n",
      "38/38 [==============================] - 78s 2s/step - loss: 0.0986 - mean_iou: 0.8935 - val_loss: 0.0847 - val_mean_iou: 0.9138\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08903 to 0.08472, saving model to C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as down_conv_64_layer_call_and_return_conditional_losses, down_conv_64_layer_call_fn, conv2d_265_layer_call_and_return_conditional_losses, conv2d_265_layer_call_fn, down_conv_60_layer_call_and_return_conditional_losses while saving (showing 5 of 185). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/sinjy/jupyter_notebook/model\\model-dsbow\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "38/38 [==============================] - 82s 2s/step - loss: 0.0959 - mean_iou: 0.8962 - val_loss: 0.0938 - val_mean_iou: 0.9103\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.08472\n",
      "Epoch 17/50\n",
      "38/38 [==============================] - 82s 2s/step - loss: 0.0946 - mean_iou: 0.8979 - val_loss: 0.0923 - val_mean_iou: 0.9103\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08472\n",
      "Epoch 18/50\n",
      "38/38 [==============================] - 83s 2s/step - loss: 0.0962 - mean_iou: 0.8957 - val_loss: 0.0876 - val_mean_iou: 0.9113\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.08472\n",
      "Epoch 19/50\n",
      "38/38 [==============================] - 83s 2s/step - loss: 0.0910 - mean_iou: 0.9009 - val_loss: 0.0875 - val_mean_iou: 0.9147\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.08472\n",
      "Epoch 20/50\n",
      "38/38 [==============================] - 83s 2s/step - loss: 0.0923 - mean_iou: 0.8998 - val_loss: 0.0875 - val_mean_iou: 0.9106\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08472\n",
      "Epoch 00020: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint(\n",
    "    'C:/Users/sinjy/jupyter_notebook/model/model-dsbow', verbose=1, \n",
    "    save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, \n",
    "                   epochs=50, callbacks=[earlystopper, checkpointer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning",
   "language": "python",
   "name": "machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
